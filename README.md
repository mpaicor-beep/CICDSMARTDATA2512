<div align="center">

# ğŸ GestiÃ³n de Costos de Proyectos ETL Pipeline
### Arquitectura Medallion en Azure Databricks

[![Databricks](https://img.shields.io/badge/Databricks-FF3621?style=for-the-badge&logo=databricks&logoColor=white)](https://databricks.com/)
[![Azure](https://img.shields.io/badge/Azure-0078D4?style=for-the-badge&logo=microsoft-azure&logoColor=white)](https://azure.microsoft.com/)
[![PySpark](https://img.shields.io/badge/PySpark-E25A1C?style=for-the-badge&logo=apache-spark&logoColor=white)](https://spark.apache.org/)
[![Delta Lake](https://img.shields.io/badge/Delta_Lake-00ADD8?style=for-the-badge&logo=delta&logoColor=white)](https://delta.io/)
[![CI/CD](https://img.shields.io/badge/CI%2FCD-GitHub_Actions-2088FF?style=for-the-badge&logo=github-actions&logoColor=white)](https://github.com/features/actions)

*Pipeline automatizado de datos para anÃ¡lisis de costos de proyectos con arquitectura de tres capas y despliegue continuo*

</div>

---

## ğŸ¯ DescripciÃ³n

Pipeline ETL enterprise-grade que transforma datos crudos de costos de Proyectos, implementando la **Arquitectura Medallion** (Bronze-Silver-Gold) en Azure Databricks con **CI/CD completo** y **Delta Lake** para garantizar consistencia ACID.

### âœ¨ CaracterÃ­sticas Principales

- ğŸ”„ **ETL Automatizado** - Pipeline completo con despliegue automÃ¡tico via GitHub Actions
- ğŸ—ï¸ **Arquitectura Medallion** - SeparaciÃ³n clara de capas Bronze â†’ Silver â†’ Gold
- ğŸ“Š **Modelo Dimensional** - Star Schema optimizado para anÃ¡lisis de negocio
- ğŸš€ **CI/CD Integrado** - Deploy automÃ¡tico en cada push a master
- ğŸ“ˆ **Databricks Dashboards** - VisualizaciÃ³n
- âš¡ **Delta Lake** - ACID transactions y time travel capabilities
- ğŸ”” **Monitoreo** - Notificaciones automÃ¡ticas y logs detallados

---

## ğŸ›ï¸ Arquitectura

### Flujo de Datos

```
ğŸ“„ CSV (Raw Data)
    â†“
ğŸ¥‰ Bronze Layer (Ingesta sin transformaciÃ³n)
    â†“
ğŸ¥ˆ Silver Layer (Limpieza + Modelo Dimensional)
    â†“
ğŸ¥‡ Gold Layer (Agregaciones de Negocio)
    â†“
ğŸ“Š Databricks Dashboards (VisualizaciÃ³n)
```

### ğŸ“¦ Capas del Pipeline

<table>
<tr>
<td width="33%" valign="top">

#### ğŸ¥‰ Bronze Layer
**PropÃ³sito**: Zona de aterrizaje

**Tablas**: 
- `consumos` 
- `proyectos`

**CaracterÃ­sticas**:
- âœ… Datos tal como vienen de origen
- âœ… Timestamp de ingesta
- âœ… PreservaciÃ³n histÃ³rica
- âœ… Sin validaciones

</td>
<td width="33%" valign="top">

#### ğŸ¥ˆ Silver Layer
**PropÃ³sito**: Modelo dimensional

**Tablas**:
- `golden_costos_partitioned`
- `costos_transformed`

**CaracterÃ­sticas**:
- âœ… Star Schema
- âœ… Datos normalizados
- âœ… Validaciones completas

</td>
<td width="33%" valign="top">

#### ğŸ¥‡ Gold Layer
**PropÃ³sito**: Analytics-ready

**Tablas**:
- kpi_costos        : Monto total de costos agrupado por categorÃ­a y aÃ±o

**CaracterÃ­sticas**:
- âœ… Pre-agregados
- âœ… Optimizado para BI
- âœ… Performance mÃ¡ximo
- âœ… Actualizaciones automÃ¡ticas

</td>
</tr>
</table>

---

## ğŸ“ Estructura del Proyecto

```
etl-apple/
â”‚
â”œâ”€â”€ ğŸ“‚ .github/
â”‚   â””â”€â”€ ğŸ“‚ workflows/
â”‚       â””â”€â”€ ğŸ“„ deploy-notebook.yml    # Pipeline CI/CD deploy a certification workspace databricks
â”œâ”€â”€ ğŸ“‚ process/
â”‚   â”œâ”€â”€ ğŸ Ingest_consumos_data.py           # Bronze layer
â”‚   â”œâ”€â”€ ğŸ Ingest_proyectos_data.py         # Bronze Layer
â”‚   â”œâ”€â”€ ğŸ transform_data.py             # Silver Layer
â”‚   â””â”€â”€ ğŸ load_data.py                # Gold Layer
â”œâ”€â”€ ğŸ“‚ scrips/
|   â”œâ”€â”€ ğŸ Preparacion_Ambiente.py    # Create Schema, Tables, External location
â”œâ”€â”€ ğŸ“‚ security/
|   â”œâ”€â”€ ğŸ Grants-Medallion.py               # Sql Grant
â”œâ”€â”€ ğŸ“‚ reversion/
|   â”œâ”€â”€ ğŸ revoke.py               # Revoke permissions
â”œâ”€â”€ ğŸ“‚ dashboards/                 # PowerBI Dashboard 
â””â”€â”€ ğŸ“„ README.md
```

---

## ğŸ› ï¸ TecnologÃ­as

<div align="center">

| TecnologÃ­a | PropÃ³sito |
|:----------:|:----------|
| ![Databricks](https://img.shields.io/badge/Azure_Databricks-FF3621?style=flat-square&logo=databricks&logoColor=white) | Motor de procesamiento distribuido Spark |
| ![Delta Lake](https://img.shields.io/badge/Delta_Lake-00ADD8?style=flat-square&logo=delta&logoColor=white) | Storage layer con ACID transactions |
| ![PySpark](https://img.shields.io/badge/PySpark-E25A1C?style=flat-square&logo=apache-spark&logoColor=white) | Framework de transformaciÃ³n de datos |
| ![ADLS](https://img.shields.io/badge/ADLS_Gen2-0078D4?style=flat-square&logo=microsoft-azure&logoColor=white) | Data Lake para almacenamiento persistente |
| ![GitHub Actions](https://img.shields.io/badge/GitHub_Actions-2088FF?style=flat-square&logo=github-actions&logoColor=white) | AutomatizaciÃ³n CI/CD |
| [PowerBI Dashboards] |  VisualizaciÃ³n |

</div>

---

## âš™ï¸ Requisitos Previos

- â˜ï¸ Cuenta de Azure con acceso a Databricks
- ğŸ’» Workspace de Databricks configurado
- ğŸ–¥ï¸ Cluster activo (nombre: `ClusterSD`)
- ğŸ™ Cuenta de GitHub con permisos de administrador
- ğŸ“¦ Azure Data Lake Storage Gen2 configurado
- ğŸ“Š Power BI Desktop (opcional para visualizaciÃ³n)

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1ï¸âƒ£ Clonar el Repositorio

```bash
git clone https://github.com/mpaicor-beep/CICDSMARTDATA2512.git
cd project-databricks
```

### 2ï¸âƒ£ Configurar Databricks Token

1. Ir a Databricks Workspace
2. **User Settings** â†’ **Developer** â†’ **Access Tokens**
3. Click en **Generate New Token**
4. Configurar:
   - **Comment**: `GitHub CI/CD`
   - **Lifetime**: `90 days`
5. âš ï¸ Copiar y guardar el token

### 3ï¸âƒ£ Configurar GitHub Secrets

En tu repositorio: **Settings** â†’ **Secrets and variables** â†’ **Actions**

| Secret Name | Valor Ejemplo |
|------------|---------------|
| `DATABRICKS_HOST` | `https://adb-xxxxx.azuredatabricks.net` |
| `DATABRICKS_TOKEN` | `dapi_xxxxxxxxxxxxxxxx` |

### 4ï¸âƒ£ Verificar Storage Configuration

```python
storage_path = "abfss://raw@adlssmartdata202512.dfs.core.windows.net"
```

<div align="center">

âœ… **Â¡ConfiguraciÃ³n completa!**

</div>

---

## ğŸ’» Uso

### ğŸ”„ Despliegue AutomÃ¡tico (Recomendado)

```bash
git add .
git commit -m "âœ¨ feat: mejoras en pipeline"
git push origin master
```

**GitHub Actions ejecutarÃ¡**:
- ğŸ“¤ Deploy de notebooks a `/Production/ETL-COSTOS`
- ğŸ”§ CreaciÃ³n del workflow `WF_COSTOS`
- â–¶ï¸ EjecuciÃ³n completa:  Bronze â†’ Silver â†’ Gold
- ğŸ“§ Notificaciones de resultados

### ğŸ–±ï¸ Despliegue Manual desde GitHub

1. Ir al tab **Actions** en GitHub
2. Seleccionar **Deploy ETL Control de Costos**
3. Click en **Run workflow**
4. Seleccionar rama `main`
5. Click en **Run workflow**

### ğŸ”§ EjecuciÃ³n Local en Databricks

Navegar a `/Production/ETL-GestiÃ³n de Costos de Pytos` y ejecutar en orden:

```
- Preparacion_Ambiente.py          â†’ Crear esquema
- Ingest_consumos_data.py          â†’ Bronze Layer
- Ingest_proyectos_data.py         â†’ Bronze Layer
- Transform_data.py                â†’ Silver Layer
- Load_data.py                     â†’ Gold Layer

```

---


## ğŸ”„ CI/CD

### Pipeline de GitHub Actions

```yaml
Workflow: Deploy GestiÃ³n de Costos de Pytos
â”œâ”€â”€ Deploy notebooks â†’ /Production/Gestion de Costos de Pytos
â”œâ”€â”€ Eliminar workflow antiguo (si existe)
â”œâ”€â”€ Buscar cluster configurado
â”œâ”€â”€ Crear nuevo workflow con 5 tareas
â”œâ”€â”€ Ejecutar pipeline automÃ¡ticamente
â””â”€â”€ Monitorear y notificar resultados
```

### ğŸ”„  Workflow Databricks
```


â° Schedule: Diario 8:00 AM (Lima)
â±ï¸ Timeout total: 4 horas
 ğŸ”’ Max concurrent runs: 1
â° Notificaciones: 
      success: mpaicor@gmail.com
      failed:  mpaicor@gmail.com
```

---

## ğŸ“ˆ Dashboards


## ğŸ” Monitoreo

### En Databricks

**Workflows**:
- Ir a **Workflows** en el menÃº lateral
- Buscar `ETL_COSTOS PROYECTOS`
- Ver historial de ejecuciones

**Logs por Tarea**:
- Click en una ejecuciÃ³n especÃ­fica
- Click en cada tarea para ver logs detallados
- Revisar stdout/stderr en caso de errores

### En GitHub Actions

- Tab **Actions** del repositorio
- Ver historial de workflows
- Click en ejecuciÃ³n especÃ­fica para detalles
- Revisar logs de cada step

---

## ğŸ‘¤ Autor

<div align="center">

### Milagros BetzabÃ© Paico Ramirez

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)]([(https://www.linkedin.com/in/milagros-paico-432175b4/))
[![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/mpaicor-beep)
[![Email](https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:mpaicor@gmail.com)

**Data Governance** | **Data Engineering** | **Azure Databricks** | **Delta Lake** | **CI/CD**

</div>

---

---

<div align="center">

**Proyecto**: Data Engineering - Arquitectura Medallion  
**TecnologÃ­a**: Azure Databricks + Delta Lake + CI/CD  
**Ãšltima actualizaciÃ³n**: 2025


</div>
